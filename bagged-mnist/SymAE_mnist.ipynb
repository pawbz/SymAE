{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name=\"mnist\"\n",
    "fname=\"/home/pawan/Dropbox/SymAE/\"+expt_name\n",
    "fnametest=\"/home/pawan/Dropbox/SymAE/test\"+expt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Xo_train (10000, 20, 28, 28, 1)\n",
      "number of samples Xo_train\t 10000\n",
      "number of instances in each datapoint Xo_train\t 20\n",
      "number of samples in each channel\t (28, 28)\n"
     ]
    }
   ],
   "source": [
    "dat=h5py.File(fname+\".h5\", 'r')\n",
    "# dattest=h5py.File(fnametest+\".h5\", 'r')\n",
    "Xo_train=np.array(dat[\"data\"])\n",
    "# Xo_test=np.array(dattest[\"data\"])\n",
    "\n",
    "# Xo_train=np.expand_dims(Xo_train,[3])\n",
    "#Xo_test=np.expand_dims(Xo_test,[3])\n",
    "    \n",
    "nsamp, ntau, n1, n2, nfilt=Xo_train.shape\n",
    "with open(str(fname+'.json')) as f:\n",
    "    labels_train = json.load(f)\n",
    "labels_train=[labels_train[str(i)] for i in range(1,nsamp+1)]\n",
    "#with open(str(fnametest+'.json')) as f:\n",
    "#    labels_test = json.load(f)\n",
    "#labels_test=[labels_test[str(i)] for i in range(1,3)]\n",
    "\n",
    "\n",
    "print(\"shape of Xo_train\",np.shape(Xo_train))\n",
    "#print(\"shape of Xo_test\",np.shape(Xo_test))\n",
    "print(\"number of samples Xo_train\\t\", nsamp)\n",
    "print(\"number of instances in each datapoint Xo_train\\t\", ntau)\n",
    "print(\"number of samples in each channel\\t\", (n1,n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Xo_train, labels_train, Xo_test, labels_test=read_datapoints(fname, fnametest)\n",
    "# nsamp, ntau,n1,n2,nfilt=Xo_train.shape\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# Xo_train, Xo_test=train_test_split(Xo, test_size=0.1, shuffle=True)\n",
    "# Xo_train, labels_train=shuffle(Xo_train, labels_train, n_samples=9000)\n",
    "Xo_train, Xo_test, labels_train, labels_test=train_test_split(Xo_train, labels_train, test_size=0.1, shuffle=True)\n",
    "nsamp, ntau, n1,n2,nfilt =Xo_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "%run ../symae_core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                                              Output Shape                                                                    Param #                       \n",
      "========================================================================================================================================================================================================\n",
      "encoder_input (InputLayer)                                                                [(None, 20, 28, 28, 1)]                                                         0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          1664                          \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_35 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistributed)                                                     (None, 20, 7, 7, 64)                                                            0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLambda)                                                        (None, 7, 7, 64)                                                                0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)                                                                        (None, 7, 7, 64)                                                                102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)                                                                        (None, 7, 7, 64)                                                                102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D)                                                           (None, 3, 3, 64)                                                                0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)                                                                        (None, 3, 3, 64)                                                                102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)                                                                        (None, 3, 3, 64)                                                                102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNormalization)                                                (None, 3, 3, 64)                                                                256                           \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "activation_3 (Activation)                                                                 (None, 3, 3, 64)                                                                0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D)                                                           (None, 3, 3, 64)                                                                0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)                                                                       (None, 576)                                                                     0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                                                                           (None, 2)                                                                       1154                          \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 720,322\n",
      "Trainable params: 720,194\n",
      "Non-trainable params: 128\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                                              Output Shape                                                                    Param #                       \n",
      "========================================================================================================================================================================================================\n",
      "encoder_input (InputLayer)                                                                [(None, 20, 28, 28, 1)]                                                         0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          1664                          \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_43 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistributed)                                                     (None, 20, 7, 7, 64)                                                            0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_45 (TimeDistributed)                                                     (None, 20, 7, 7, 64)                                                            102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_46 (TimeDistributed)                                                     (None, 20, 7, 7, 64)                                                            102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_47 (TimeDistributed)                                                     (None, 20, 3, 3, 64)                                                            0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_48 (TimeDistributed)                                                     (None, 20, 3, 3, 32)                                                            51232                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistributed)                                                     (None, 20, 3, 3, 64)                                                            51264                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_50 (TimeDistributed)                                                     (None, 20, 3, 3, 64)                                                            256                           \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_51 (TimeDistributed)                                                     (None, 20, 3, 3, 64)                                                            0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistributed)                                                     (None, 20, 3, 3, 64)                                                            0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistributed)                                                     (None, 20, 576)                                                                 0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_54 (TimeDistributed)                                                     (None, 20, 5)                                                                   2885                          \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 619,621\n",
      "Trainable params: 619,493\n",
      "Non-trainable params: 128\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Model: \"model_6\"\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
      "========================================================================================================================================================================================================\n",
      "latentcode (InputLayer)                                           [(None, 102)]                               0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "tf.split_1 (TFOpLambda)                                           [(None, 2), (None, 100)]                    0                       latentcode[0][0]                                                  \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)                                    (None, 20, 2)                               0                       tf.split_1[0][0]                                                  \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)                                               (None, 20, 5)                               0                       tf.split_1[0][1]                                                  \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)                                       (None, 20, 7)                               0                       repeat_vector_1[0][0]                                             \n",
      "                                                                                                                                      reshape_2[0][0]                                                   \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                                              Output Shape                                                                    Param #                       \n",
      "========================================================================================================================================================================================================\n",
      "input_2 (InputLayer)                                                                      [(None, 20, 7)]                                                                 0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_55 (TimeDistributed)                                                     (None, 20, 196)                                                                 1568                          \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistributed)                                                     (None, 20, 14, 14, 1)                                                           0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistributed)                                                     (None, 20, 14, 14, 64)                                                          1664                          \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          256                           \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_64 (TimeDistributed)                                                     (None, 20, 28, 28, 64)                                                          102464                        \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "time_distributed_65 (TimeDistributed)                                                     (None, 20, 28, 28, 1)                                                           1601                          \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 414,945\n",
      "Trainable params: 414,817\n",
      "Non-trainable params: 128\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\",\"/gpu:2\",\"/gpu:3\",\"/gpu:4\",\"/gpu:5\",\"/gpu:6\",\"gpu:7\"])\n",
    "strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
    "# strategy = tf.distribute.get_strategy()\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"gpu:7\"])\n",
    "# strategy = tf.distribute.experimental.CentralStorageStrategy() \n",
    "#%% model\n",
    "with strategy.scope():\n",
    "    \n",
    "    \n",
    "    encoder_input=tfk.Input(shape=(ntau,n1,n2,1), dtype='float32', name='encoder_input')\n",
    "    \n",
    "#     downsampler=Downsampler([2,25],8,2)\n",
    "#     downsampler=DownsamplerDense(200,nt)\n",
    "#     xd=downsampler(encoder_input)\n",
    "\n",
    "#     downsampler.summary(line_length=120)\n",
    "#     tf.keras.utils.plot_model( downsampler, to_file='encoderdown.png', show_shapes=True, 4\n",
    "    kernel_size=(5,5)\n",
    "    nfilt=64\n",
    "    \n",
    "    nz0=2\n",
    "    symencoder1=SymmetricEncoder(kernel_size,nfilt,[2,2,2,1],[2,2,2,1],nz0)\n",
    "    xz0=symencoder1(encoder_input)\n",
    "    \n",
    "    z0=tfkl.Flatten()(xz0)\n",
    "    \n",
    "    nz0=z0.get_shape()[1]\n",
    "    \n",
    "    report(symencoder1.model(encoder_input),\"symencoder\")\n",
    "    symencoder=tf.keras.Model(encoder_input, z0, name=\"symencoder\")\n",
    "    \n",
    "    \n",
    "    nzi=5\n",
    "    nencoder1=NuisanceEncoder(kernel_size,nfilt,[2,2,2,1],[2,2,2,1],nfilt,nzi)\n",
    "    \n",
    "    xzi=nencoder1(encoder_input)\n",
    "\n",
    "    zi=tfkl.Flatten()(xzi)\n",
    "\n",
    "    report(nencoder1.model(encoder_input),\"nencoder\")\n",
    "    nencoder=tf.keras.Model(encoder_input, zi, name=\"nencoder\")\n",
    "    \n",
    "    decoder_input = tf.keras.Input(shape=(nzi*ntau+nz0), name='latentcode')\n",
    "    \n",
    "    distzsym=DistributeZsym(ntau, nz0, nzi)\n",
    "    xdhat=distzsym(decoder_input)\n",
    "    \n",
    "    report(distzsym.model(decoder_input),\"distzsym\")\n",
    "\n",
    "    mixer=Mixer(kernel_size,nfilt,(2,2),n1,n2)\n",
    "    xhat=mixer(xdhat)\n",
    "\n",
    "#     upsampler=Upsampler([2,25],8,2)\n",
    "#     upsampler=UpsamplerDense(nt,200)\n",
    "#     xhat=upsampler(xdhat)\n",
    "    \n",
    "    znuisance=nencoder(encoder_input)\n",
    "    zsym=symencoder(encoder_input)\n",
    "    \n",
    "    \n",
    "    report(mixer.model(tfk.Input(shape=(ntau,nzi+nz0))),\"mixer\")\n",
    "    \n",
    "#     report(upsampler,\"upsampler\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                                              Output Shape                                                                    Param #                       \n",
      "========================================================================================================================================================================================================\n",
      "latentcode (InputLayer)                                                                   [(None, 102)]                                                                   0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "distribute_zsym_1 (DistributeZsym)                                                        (None, 20, 7)                                                                   0                             \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "mixer_1 (Mixer)                                                                           (None, 20, 28, 28, 1)                                                           414945                        \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 414,945\n",
      "Trainable params: 414,817\n",
      "Non-trainable params: 128\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
      "========================================================================================================================================================================================================\n",
      "encoder_input (InputLayer)                                        [(None, 20, 28, 28, 1)]                     0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "symencoder (Functional)                                           (None, 2)                                   720322                  encoder_input[0][0]                                               \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "nencoder (Functional)                                             (None, 100)                                 619621                  encoder_input[0][0]                                               \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "latent_cat_1 (LatentCat)                                          (None, 102)                                 0                       symencoder[0][0]                                                  \n",
      "                                                                                                                                      nencoder[0][0]                                                    \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "decoder (Functional)                                              (None, 20, 28, 28, 1)                       414945                  latent_cat_1[1][0]                                                \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 1,754,888\n",
      "Trainable params: 1,754,504\n",
      "Non-trainable params: 384\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with strategy.scope():\n",
    "    latentcat=LatentCat(0.5)\n",
    "    \n",
    "    encoder=tf.keras.Model(encoder_input, latentcat(zsym,znuisance), name=\"encoder\")\n",
    "\n",
    "    decoder=tf.keras.Model(decoder_input, xhat, name=\"decoder\")\n",
    "    report(decoder, \"decoder\")\n",
    "    \n",
    "    model=tf.keras.Model(encoder_input, decoder(latentcat(zsym,znuisance)) , name='autoencoder')\n",
    "    report(model, \"autoencoder\")\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size=8\n",
    "ds_train=tf.data.Dataset.from_tensor_slices((Xo_train, Xo_train))\n",
    "# ds_train = tf.data.TFRecordDataset(filenames=[\"Xo.tfrecords\"])\n",
    "#   print(ds_train)\n",
    "ds_train = ds_train.shuffle(nsamp,reshuffle_each_iteration=True) \n",
    "ds_train=ds_train.batch(batch_size)\n",
    "# ds_train = ds_train.cache()\n",
    "# ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test=tf.data.Dataset.from_tensor_slices((Xo_test, Xo_test))\n",
    "ds_test=ds_test.batch(batch_size)\n",
    "# ds_test = ds_test.cache()\n",
    "# ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "options = tf.data.Options()\n",
    "# options.experimental_optimization.noop_elimination = True\n",
    "# options.experimental_optimization.map_vectorization.enabled = True\n",
    "# options.experimental_threading.max_intra_op_parallelism = 1 # reduces CPU usage?\n",
    "# options.experimental_optimization.apply_default_optimizations = True\n",
    "ds_train = ds_train.with_options(options)\n",
    "ds_test = ds_test.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1125/1125 [==============================] - 30s 25ms/step - loss: 0.6585 - val_loss: 0.3879\n",
      "Epoch 2/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.4342 - val_loss: 0.3366\n",
      "Epoch 3/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.4039 - val_loss: 0.3195\n",
      "Epoch 4/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3874 - val_loss: 0.3025\n",
      "Epoch 5/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3776 - val_loss: 0.3023\n",
      "Epoch 6/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3694 - val_loss: 0.2987\n",
      "Epoch 7/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3661 - val_loss: 0.2931\n",
      "Epoch 8/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3603 - val_loss: 0.2916\n",
      "Epoch 9/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3540 - val_loss: 0.2791\n",
      "Epoch 10/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3484 - val_loss: 0.2804\n",
      "Epoch 11/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3437 - val_loss: 0.2825\n",
      "Epoch 12/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3390 - val_loss: 0.2811\n",
      "Epoch 13/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3399 - val_loss: 0.2781\n",
      "Epoch 14/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3344 - val_loss: 0.2709\n",
      "Epoch 15/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3311 - val_loss: 0.2681\n",
      "Epoch 16/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3292 - val_loss: 0.2668\n",
      "Epoch 17/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3268 - val_loss: 0.2683\n",
      "Epoch 18/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3257 - val_loss: 0.2672\n",
      "Epoch 19/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3232 - val_loss: 0.2657\n",
      "Epoch 20/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3203 - val_loss: 0.2664\n",
      "Epoch 21/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3200 - val_loss: 0.2672\n",
      "Epoch 22/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3186 - val_loss: 0.2732\n",
      "Epoch 23/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3167 - val_loss: 0.2702\n",
      "Epoch 24/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3173 - val_loss: 0.2604\n",
      "Epoch 25/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3166 - val_loss: 0.2610\n",
      "Epoch 26/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3128 - val_loss: 0.2599\n",
      "Epoch 27/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3137 - val_loss: 0.2608\n",
      "Epoch 28/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3119 - val_loss: 0.2653\n",
      "Epoch 29/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3121 - val_loss: 0.2593\n",
      "Epoch 30/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3094 - val_loss: 0.2603\n",
      "Epoch 31/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3105 - val_loss: 0.2627\n",
      "Epoch 32/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3079 - val_loss: 0.2596\n",
      "Epoch 33/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3061 - val_loss: 0.2578\n",
      "Epoch 34/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3070 - val_loss: 0.2560\n",
      "Epoch 35/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3069 - val_loss: 0.2591\n",
      "Epoch 36/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3054 - val_loss: 0.2539\n",
      "Epoch 37/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3050 - val_loss: 0.2574\n",
      "Epoch 38/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3039 - val_loss: 0.2613\n",
      "Epoch 39/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3032 - val_loss: 0.2605\n",
      "Epoch 40/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3032 - val_loss: 0.2523\n",
      "Epoch 41/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3022 - val_loss: 0.2601\n",
      "Epoch 42/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3029 - val_loss: 0.2525\n",
      "Epoch 43/500\n",
      "1125/1125 [==============================] - 28s 25ms/step - loss: 0.3018 - val_loss: 0.2585\n",
      "Epoch 44/500\n",
      " 315/1125 [=======>......................] - ETA: 19s - loss: 0.3021"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a8b64a069932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model.fit(Xr,Xr,epochs=10, batch_size=batch_size,  callbacks=[generate_and_save_images(), history], validation_split=0.1, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model.fit(Xo,Xo,epochs=100, batch_size=batch_size, callbacks=[tbCallBack], shuffle=True, validation_split=0.05)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# model.fit(ds_train,epochs=40 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# model.fit(Xo,Xo,epochs=1,  batch_size=4)#, callbacks=[tbCallBack])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=base_dir + expt_name + '_TFmodel_save', save_weights_only=True, verbose=1)\n",
    "#model.fit(Xr,Xr,epochs=10, batch_size=batch_size,  callbacks=[cp_callback, generate_and_save_images(), history], validation_split=0.1, shuffle=True)\n",
    "#model.fit(Xr,Xr,epochs=10, batch_size=batch_size,  callbacks=[generate_and_save_images(), history], validation_split=0.1, shuffle=True)\n",
    "# model.fit(Xo,Xo,epochs=100, batch_size=batch_size, callbacks=[tbCallBack], shuffle=True, validation_split=0.05)\n",
    "history=model.fit(ds_train,epochs=500,  shuffle=True, validation_data=ds_test)\n",
    "# model.fit(ds_train,epochs=40 )\n",
    "# model.fit(Xo,Xo,epochs=1,  batch_size=4)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../plots.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_indices7986,1606\n",
      "01-02-2021_11/3_7986-true-0_itrue.png\n",
      "01-02-2021_11/7_1606-true-0_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-0_ii.png\n",
      "01-02-2021_11/3_7986-1606-0_ij.png\n",
      "01-02-2021_11/7_1606-1606-0_jj.png\n",
      "01-02-2021_11/7_1606-7986-0_ji.png\n",
      "01-02-2021_11/3_7986-true-1_itrue.png\n",
      "01-02-2021_11/7_1606-true-1_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-1_ii.png\n",
      "01-02-2021_11/3_7986-1606-1_ij.png\n",
      "01-02-2021_11/7_1606-1606-1_jj.png\n",
      "01-02-2021_11/7_1606-7986-1_ji.png\n",
      "01-02-2021_11/3_7986-true-2_itrue.png\n",
      "01-02-2021_11/7_1606-true-2_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-2_ii.png\n",
      "01-02-2021_11/3_7986-1606-2_ij.png\n",
      "01-02-2021_11/7_1606-1606-2_jj.png\n",
      "01-02-2021_11/7_1606-7986-2_ji.png\n",
      "01-02-2021_11/3_7986-true-3_itrue.png\n",
      "01-02-2021_11/7_1606-true-3_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-3_ii.png\n",
      "01-02-2021_11/3_7986-1606-3_ij.png\n",
      "01-02-2021_11/7_1606-1606-3_jj.png\n",
      "01-02-2021_11/7_1606-7986-3_ji.png\n",
      "01-02-2021_11/3_7986-true-4_itrue.png\n",
      "01-02-2021_11/7_1606-true-4_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-4_ii.png\n",
      "01-02-2021_11/3_7986-1606-4_ij.png\n",
      "01-02-2021_11/7_1606-1606-4_jj.png\n",
      "01-02-2021_11/7_1606-7986-4_ji.png\n",
      "01-02-2021_11/3_7986-true-5_itrue.png\n",
      "01-02-2021_11/7_1606-true-5_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-5_ii.png\n",
      "01-02-2021_11/3_7986-1606-5_ij.png\n",
      "01-02-2021_11/7_1606-1606-5_jj.png\n",
      "01-02-2021_11/7_1606-7986-5_ji.png\n",
      "01-02-2021_11/3_7986-true-6_itrue.png\n",
      "01-02-2021_11/7_1606-true-6_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-6_ii.png\n",
      "01-02-2021_11/3_7986-1606-6_ij.png\n",
      "01-02-2021_11/7_1606-1606-6_jj.png\n",
      "01-02-2021_11/7_1606-7986-6_ji.png\n",
      "01-02-2021_11/3_7986-true-7_itrue.png\n",
      "01-02-2021_11/7_1606-true-7_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-7_ii.png\n",
      "01-02-2021_11/3_7986-1606-7_ij.png\n",
      "01-02-2021_11/7_1606-1606-7_jj.png\n",
      "01-02-2021_11/7_1606-7986-7_ji.png\n",
      "01-02-2021_11/3_7986-true-8_itrue.png\n",
      "01-02-2021_11/7_1606-true-8_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-8_ii.png\n",
      "01-02-2021_11/3_7986-1606-8_ij.png\n",
      "01-02-2021_11/7_1606-1606-8_jj.png\n",
      "01-02-2021_11/7_1606-7986-8_ji.png\n",
      "01-02-2021_11/3_7986-true-9_itrue.png\n",
      "01-02-2021_11/7_1606-true-9_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-9_ii.png\n",
      "01-02-2021_11/3_7986-1606-9_ij.png\n",
      "01-02-2021_11/7_1606-1606-9_jj.png\n",
      "01-02-2021_11/7_1606-7986-9_ji.png\n",
      "01-02-2021_11/3_7986-true-10_itrue.png\n",
      "01-02-2021_11/7_1606-true-10_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-10_ii.png\n",
      "01-02-2021_11/3_7986-1606-10_ij.png\n",
      "01-02-2021_11/7_1606-1606-10_jj.png\n",
      "01-02-2021_11/7_1606-7986-10_ji.png\n",
      "01-02-2021_11/3_7986-true-11_itrue.png\n",
      "01-02-2021_11/7_1606-true-11_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-11_ii.png\n",
      "01-02-2021_11/3_7986-1606-11_ij.png\n",
      "01-02-2021_11/7_1606-1606-11_jj.png\n",
      "01-02-2021_11/7_1606-7986-11_ji.png\n",
      "01-02-2021_11/3_7986-true-12_itrue.png\n",
      "01-02-2021_11/7_1606-true-12_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-12_ii.png\n",
      "01-02-2021_11/3_7986-1606-12_ij.png\n",
      "01-02-2021_11/7_1606-1606-12_jj.png\n",
      "01-02-2021_11/7_1606-7986-12_ji.png\n",
      "01-02-2021_11/3_7986-true-13_itrue.png\n",
      "01-02-2021_11/7_1606-true-13_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-13_ii.png\n",
      "01-02-2021_11/3_7986-1606-13_ij.png\n",
      "01-02-2021_11/7_1606-1606-13_jj.png\n",
      "01-02-2021_11/7_1606-7986-13_ji.png\n",
      "01-02-2021_11/3_7986-true-14_itrue.png\n",
      "01-02-2021_11/7_1606-true-14_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-14_ii.png\n",
      "01-02-2021_11/3_7986-1606-14_ij.png\n",
      "01-02-2021_11/7_1606-1606-14_jj.png\n",
      "01-02-2021_11/7_1606-7986-14_ji.png\n",
      "01-02-2021_11/3_7986-true-15_itrue.png\n",
      "01-02-2021_11/7_1606-true-15_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-15_ii.png\n",
      "01-02-2021_11/3_7986-1606-15_ij.png\n",
      "01-02-2021_11/7_1606-1606-15_jj.png\n",
      "01-02-2021_11/7_1606-7986-15_ji.png\n",
      "01-02-2021_11/3_7986-true-16_itrue.png\n",
      "01-02-2021_11/7_1606-true-16_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-16_ii.png\n",
      "01-02-2021_11/3_7986-1606-16_ij.png\n",
      "01-02-2021_11/7_1606-1606-16_jj.png\n",
      "01-02-2021_11/7_1606-7986-16_ji.png\n",
      "01-02-2021_11/3_7986-true-17_itrue.png\n",
      "01-02-2021_11/7_1606-true-17_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-17_ii.png\n",
      "01-02-2021_11/3_7986-1606-17_ij.png\n",
      "01-02-2021_11/7_1606-1606-17_jj.png\n",
      "01-02-2021_11/7_1606-7986-17_ji.png\n",
      "01-02-2021_11/3_7986-true-18_itrue.png\n",
      "01-02-2021_11/7_1606-true-18_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-18_ii.png\n",
      "01-02-2021_11/3_7986-1606-18_ij.png\n",
      "01-02-2021_11/7_1606-1606-18_jj.png\n",
      "01-02-2021_11/7_1606-7986-18_ji.png\n",
      "01-02-2021_11/3_7986-true-19_itrue.png\n",
      "01-02-2021_11/7_1606-true-19_jtrue.png\n",
      "01-02-2021_11/3_7986-7986-19_ii.png\n",
      "01-02-2021_11/3_7986-1606-19_ij.png\n",
      "01-02-2021_11/7_1606-1606-19_jj.png\n",
      "01-02-2021_11/7_1606-7986-19_ji.png\n"
     ]
    }
   ],
   "source": [
    "plot_mnist(Xo_train, labels_train,symencoder, nencoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flatten' object has no attribute 'rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4d3a2563c566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Previous Dropout \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnew_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flatten' object has no attribute 'rate'"
     ]
    }
   ],
   "source": [
    "print(\"Previous Dropout \"+str(model.layers[2].layers[-1].rate))\n",
    "model.save_weights(\"temp_weights\")\n",
    "new_dropout=0.5\n",
    "model.layers[2].layers[-1].rate=new_dropout\n",
    "model = tfk.models.clone_model(model)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.load_weights(\"temp_weights\")\n",
    "print(\"New Dropout \"+str(model.layers[2].layers[-2].rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labelindices={'base0': [], 'moni1' : [], 'moni2' : []}\n",
    "for (i,label) in enumerate(labels):\n",
    "    labelindices[label[0][0]].append(i)\n",
    "\n",
    "\n",
    "# In[281]:\n",
    "\n",
    "\n",
    "labels[labelindices['moni2']][0][0]\n",
    "\n",
    "\n",
    "# # Visualize Latent Space\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "# visualizing latent space\n",
    "\n",
    "\"\"\"\n",
    "fig=plt.figure(dpi=100, figsize=(15,8))\n",
    "for label in ['100', '200', '300', '400', '500']:\n",
    "    i = labelindices[label][0:1]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        latentsr=encoderr(Xo[i])\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "with tf.device('/gpu'):\n",
    "    test_large_indices = [np.random.randint(1, nsamp) for i in range(0,64)]\n",
    "    latentsT=nencoder.predict(Xo_train                           [test_large_indices])\n",
    "    latentsr=symencoder.predict(Xo_train[test_large_indices])\n",
    "    #print(np.shape(latentsr))\n",
    "    fig, axs = plt.subplots(2, 2, dpi=100, figsize=(15,8))\n",
    "    a=axs[0,0].imshow(latentsr, aspect=1)\n",
    "    #for l in latentsr:\n",
    "    #    a=axs[0,0].plot(l)\n",
    "    axs[0,0].set_title('G')\n",
    "    plt.colorbar(a, ax=axs[0,0]) \n",
    "\n",
    "    #a=axs[1,0].imshow(tf.exp(latentsr[1]), aspect=1)\n",
    "    #axs[1,0].set_title('sigma encoderr output for samples')\n",
    "    #plt.colorbar(a, ax=axs[1,0]) \n",
    "\n",
    "    b=axs[0,1].imshow(latentsT, aspect=1)\n",
    "    axs[0,1].set_title('Z')\n",
    "    plt.colorbar(b, ax=axs[0,1]) \n",
    "    \n",
    "plt.gcf()\n",
    "#b=axs[1,1].imshow(tf.exp(latentsT[1]), aspect=1)\n",
    "#axs[1,1].set_title('sigma encoderT output for samples')\n",
    "#plt.colorbar(b, ax=axs[1,1]) \n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "plt.imshow(latentsT)\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "with tf.device('/gpu'):\n",
    "    latentsr={'base0': [], 'moni1':[],'moni2':[]}\n",
    "    for label in ['base0', 'moni1', 'moni2']:\n",
    "        i = labelindices[label][1:20]\n",
    "        with tf.device('/gpu:0'):\n",
    "            latentsr[label]=symencoder.predict(Xo_train[i])\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,5,dpi=500, figsize=(3,2))\n",
    "markers=['r', 'b', 'c', 'g', 'm']\n",
    "subs=['(a)', '(b)', '(c)', '(d)', '(e)']\n",
    "for (i,label) in enumerate(['base0', 'moni1', 'moni2', 'base0', 'base0']):\n",
    "    lmean=np.mean(latentsr[label], axis=0)\n",
    "    #ax[i].plot(lmean, color='k', linewidth=0.1)\n",
    "    ax[1,i].imshow(latentsr[label].T)\n",
    "    # Hide grid lines\n",
    "    ax[1,i].grid(False)\n",
    "#     Hide axes ticks\n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "    ax[1,i].set_xlabel('$\\tau$')\n",
    "    ax[1,i].set_ylabel('$Z_g$')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax[0,i].imshow(vp[label].T, cmap='RdBu')\n",
    "    ax[0,i].axis('off')\n",
    "    ax[0,i].set_xlabel('$x$')\n",
    "    ax[0,i].set_ylabel('$z$')\n",
    "    ax[0,i].set_title(subs[i]+'$\\epsilon=$'+str(i))\n",
    "\n",
    "\n",
    "    #for l in latentsr[label]:\n",
    "     #   ax[i].fill_between(range(0,96), l, lmean, color=markers[i], alpha=0.1)\n",
    "        #ax[i].set_xlabel()\n",
    "        \n",
    "plt.gcf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tf.keras.models.save_model(model, '_TFmodel')\n",
    "tf.keras.models.save_model(symencoder, '_TFencoderr')\n",
    "tf.keras.models.save_model(nencoder, '_TFencodertau')\n",
    "# tf.keras.models.save_model(encoder, '_TFencoder')\n",
    "tf.keras.models.save_model(decoder, '_TFdecoder')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
