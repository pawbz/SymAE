
using Flux, MLUtils, Statistics, OneHotArrays
xpu = gpu

"""
Returns data iterator `X` where each datapoint is generated by randomly picking  `ntau` instances from a ticular state.
During training, it is very important to mix instances from different states in each batch. In other words, a small batch size, e.g., `1`, is observed not to disentangle coherent from nuisance information. Therefore, it is recommended to set the batch size as high as possible.

* `nd` : number of output datapoints
* `ntau` : number of instances in each datapoint (typically 20)
* `dvec` : a vector where the elements are measured instances from different states
* `batchsize` : number of data points used in each batch for training
"""
function get_data_iterator(dvec; nd=1000, batchsize=256, ntau=20)
    drepeat = Flux.stack([randobs(randobs(dvec), ntau) for i = 1:nd], dims=3)
    return BatchView(drepeat, batchsize=batchsize)
end

## get networks
function get_dense_networks(nt, p, q)
    l2p = floor.(Int, LinRange(nt, 2 * p, 5))
    lq = floor.(Int, LinRange(nt, q, 5))
    lpq = floor.(Int, LinRange(p + q, nt, 5))
    senc1 =
        Chain(
            Dense(nt, l2p[2], elu),
            Dense(l2p[2], l2p[3], elu),
            Dense(l2p[3], l2p[4], elu),
            Dense(l2p[4], 2 * p),
        ) |> xpu
    senc2 = Chain(Dense(2 * p, 2 * p, elu), Dense(2 * p, p)) |> xpu

    nenc =
        Chain(
            Dense(nt, lq[2], elu),
            Dense(lq[2], lq[3], elu),
            Dense(lq[3], lq[4], elu),
            Dense(lq[4], q),
            Dropout(0.5, dims=(1, 2, 3)),
        ) |> xpu

    dec =
        Chain(
            Dense(p + q, lpq[2], elu),
            Dense(lpq[2], lpq[3], elu),
            Dense(lpq[3], lpq[4], elu),
            Dense(lpq[4], nt),
        ) |> xpu
    return (; senc1, senc2, nenc, dec)
end
##

## get networks
function get_dense_networks_new(nt, p, q1, q2)
    l2p = floor.(Int, LinRange(nt, 2 * p, 5))
    l2q = floor.(Int, LinRange(nt, q1, 5))
    lq = floor.(Int, LinRange(nt * q1, q2, 5))
    lpq = floor.(Int, LinRange(p + q2, nt, 5))
    senc1 =
        Chain(
            Dense(nt, l2p[2], elu),
            Dense(l2p[2], l2p[3], elu),
            Dense(l2p[3], l2p[4], elu),
            Dense(l2p[4], 2 * p),
        ) |> xpu
    senc2 = Chain(Dense(2 * p, 2 * p, elu), Dense(2 * p, p)) |> xpu

    nenc1 =
        Chain(
            Dense(nt, l2q[2], elu),
            Dense(l2q[2], l2q[3], elu),
            Dense(l2q[3], l2q[4], elu),
            Dense(l2q[4], q1),
        ) |> xpu

    nenc2 =
        Chain(
            Dense(nt * q1, lq[2], elu),
            Dense(lq[2], lq[3], elu),
            Dense(lq[3], lq[4], elu),
            Dense(lq[4], q2),
            Dropout(0.5, dims=(1, 2, 3)),
        ) |> xpu

    dec =
        Chain(
            Dense(p + q2, lpq[2], elu),
            Dense(lpq[2], lpq[3], elu),
            Dense(lpq[3], lpq[4], elu),
            Dense(lpq[4], nt),
        ) |> xpu
    return (; senc1, senc2, nenc1, nenc2, dec)
end

## get networks
function get_dense_networks_new2(nt, p, q1, q2)
    l2p = floor.(Int, LinRange(nt, 2 * p, 5))
    l2q = floor.(Int, LinRange(nt, q1, 5))
    lq = floor.(Int, LinRange(nt * q1, q2, 5))
    lpq = floor.(Int, LinRange(p + q2, nt, 5))
    senc1 =
        Chain(
            Dense(nt, l2p[2], elu),
            Dense(l2p[2], l2p[3], elu),
            Dense(l2p[3], l2p[4], elu),
            Dense(l2p[4], 2 * p),
        ) |> xpu
    senc2 = Chain(Dense(2 * p, 2 * p, elu), Dense(2 * p, p)) |> xpu

    nenc1 = #[
        Chain(
            Dense(1, 2, elu),
            Dense(2, 2, elu),
            Dense(2, 2, elu),
            Dense(2, 2),
        )# for i in 1:nt] |> xpu

    nenc2 =
        Chain(
            Dense(nt * q1, lq[2], elu),
            Dense(lq[2], lq[3], elu),
            Dense(lq[3], lq[4], elu),
            Dense(lq[4], q2),
            Dropout(0.5, dims=(1, 2, 3)),
        ) |> xpu

    dec =
        Chain(
            Dense(p + q2, lpq[2], elu),
            Dense(lpq[2], lpq[3], elu),
            Dense(lpq[3], lpq[4], elu),
            Dense(lpq[4], nt),
        ) |> xpu
    return (; senc1, senc2, nenc1, nenc2, dec)
end
#
#
function get_conv_networks(nt, p, q)
    senc1 = Chain(
        x -> reshape(x, size(x, 1), 1, size(x, 2)),
        Conv((5,), 1 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        MaxPool((2,)),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        MaxPool((2,)),
    ) |> xpu

    senc2 = Chain(
        Conv((5,), 64 => 32, elu, ; pad=SamePad()),
        MaxPool((2,)),
        Conv((5,), 32 => 1, ; pad=SamePad()),
        BatchNorm(1, elu),
        MaxPool((2,)),
        x -> Flux.flatten(x),
        Dense(div(nt, 16), p),
    ) |> xpu


    # 1D convolutional layers [time, channel, batch]
    nenc = Chain(
        x -> reshape(x, size(x, 1), 1, size(x, 2)),
        # Dropout(0.3, dims = (1, 2, 3)),
        Conv((5,), 1 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        # MaxPool((2,)),
        Dropout(0.4, dims=(1, 2, 3)),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 32, elu, ; pad=SamePad()),
        Dropout(0.4, dims=(1, 2, 3)),
        MaxPool((2,)),
        Conv((5,), 32 => 32, elu, ; pad=SamePad()),
        Conv((5,), 32 => 32, elu, ; pad=SamePad()),
        # MaxPool((2,)),
        Dropout(0.4, dims=(1, 2, 3)),
        Conv((5,), 32 => 8, elu, ; pad=SamePad()),
        Conv((5,), 8 => 1, ; pad=SamePad()),
        BatchNorm(1, elu),
        # MaxPool((2,)),
        x -> Flux.flatten(x),
        Dense(div(nt, 2), q),
        Dropout(0.4, dims=(1, 2, 3)),
    ) |> xpu



    dec = Chain(
        Dense(p + q, div(nt, 8), elu),
        x -> reshape(x, size(x, 1), 1, size(x, 2)),
        Conv((5,), 1 => 64, elu, ; pad=SamePad()),
        Upsample(8),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 64, ; pad=SamePad()),
        BatchNorm(64, elu),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 64, elu, ; pad=SamePad()),
        Conv((5,), 64 => 1, ; pad=SamePad()),
    ) |> xpu

    return (; senc1, senc2, nenc, dec)
end

struct BroadcastSenc
    senc1::Chain
    senc2::Chain
end
struct BroadcastNenc
    chain::Chain
end
struct BroadcastNenc_new{T}
    nenc1::Chain
    nenc2::Chain
    E::T
end
struct BroadcastNenc_new2{T}
    nenc1::T
    nenc2::Chain
end
struct BroadcastDec
    chain::Chain
end
struct JoinEncs{T1,T2}
    senc::T1
    nenc::T2
end

function (m::BroadcastSenc)(x)
    x = cat(x, dims=3)
    n = size(x)
    X = reshape(x, n[1:end-2]..., n[end-1] * n[end])
    X = m.senc1(X)
    n1 = size(X)
    X = reshape(X, n1[1:end-1]..., n[end-1], n[end])
    X = mean(X, dims=ndims(X) - 1)
    X = dropdims(X, dims=ndims(X) - 1)
    X = m.senc2(X)
    X = Flux.stack(fill(X, n[end-1]), dims=length(n) - 1)
    return X
end
function (m::BroadcastNenc)(x)
    x = cat(x, dims=3)
    n1, n2, n3 = size(x)
    X = reshape(x, :, n2 * n3)
    X = m.chain(X)
    X = reshape(X, :, n2, n3)
    return X
end
function (m::BroadcastNenc_new)(x)
    x = cat(x, dims=3)

    X = mapreduce(vcat, m.E) do e
        m.nenc1(x .* e)
    end
    X = m.nenc2(X)
    return X
end

function (m::BroadcastNenc_new2)(x)
    x = cat(x, dims=3)
        @show size(x)
    n1, n2, n3 = size(x)
    x = chunk(x, n1, dims=1)
    X = mapreduce(vcat, x,) do xx
        xx=reshape(xx, 1, n2, n3)
        # @show size(xx)
        return  m.nenc1(xx)
    end
    X = m.nenc2(X)
    return X
end
function (m::BroadcastDec)(x)
    x = cat(x, dims=3)
    n1, n2, n3 = size(x)
    X = reshape(x, :, n2 * n3)
    X = m.chain(X)
    X = reshape(X, :, n2, n3)
    return X
end
function (m::JoinEncs)(x)
    return cat(m.senc(x), m.nenc(x), dims=1)
end
Flux.@functor BroadcastSenc
Flux.@functor BroadcastNenc
Flux.@functor BroadcastDec
Flux.@functor JoinEncs





function partial_nenc(d)
    N = Zygote.jacobian(NN.nenc, d)
    n = NN.nenc(d)
    c = sencb(d)
    M = Zygote.jacobian(n) do nn
        NN.dec(cat(c, nn, dims=1))
    end
    return M[1] * N[1]
end


function partial_nenc(d0, d)
    N = Zygote.jacobian(NN.nenc, d)
    n = NN.nenc(d)
    c = sencb(d0)
    M = Zygote.jacobian(n) do nn
        NN.dec(cat(c, nn, dims=1))
    end
    return M[1] * N[1]
end

function partial_senc(d)
    N = Zygote.jacobian(sencb, d)
    n = NN.nenc(d)
    c = sencb(d)
    M = Zygote.jacobian(c) do cc
        NN.dec(cat(cc, n, dims=1))
    end
    return M[1] * N[1]
end

function norm_partial_senc(d)
    mapreduce(+, eachslice(d, dims=2)) do dd
        B = partial_senc(dd)
        return norm(B, 2) / sqrt(length(dd))
    end
end
function norm_partial_nenc(d)
    mapreduce(+, eachslice(d, dims=2)) do dd
        B = partial_nenc(dd)
        return norm(B, 2) / sqrt(length(dd))
    end
end